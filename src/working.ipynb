{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data\n",
    "import topicmodeling as tp\n",
    "import gensim as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gather Python entities from libraries\n",
    "l_interested = data.get_entity_list(data.libinfo.interested_libs)\n",
    "l_code = list(map(data.get_code, l_interested))\n",
    "l_doc = list(map(data.get_doc, l_interested))\n",
    "l_doc = list(map(lambda doc : data.pdoc.extract(doc, stage=data.pdoc.ADVANCED), l_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# analyse comment part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert documentations to bag of words\n",
    "documents = l_doc\n",
    "texts = tp.simple_process(documents=documents, stoplist=tp.read_stoplist(\"../SmartStoplist.txt\"))\n",
    "texts = tp.remove_infrequent(texts, n_times=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id2word = g.corpora.Dictionary(texts)\n",
    "#id2word.save('/tmp/deerwester.dict') # store the id2word, for future reference\n",
    "print(*list(id2word)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "#g.corpora.corpusCorpus.serialize('/tmp/deerwester.mm', corpus) # store to disk, for later use\n",
    "print(*list(corpus)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load id->word mapping (the id2word), one of the results of step 2 above\n",
    "#id2word = g.g.corpora.id2word.load_from_text('wiki_en_wordids.txt')\n",
    "# load corpus iterator\n",
    "#corpus = g.corpora.MmCorpus('/tmp/deerwester.mm')\n",
    "#corpus = g.g.corpora.MmCorpus(bz2.BZ2File('wiki_en_tfidf.mm.bz2')) # use this if you compressed the TFIDF output (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## extract 100 LDA topics, using 1 pass and updating once every 1 chunk (10,000 documents)\n",
    "lda = g.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=n_topics, \n",
    "                                 update_every=1, chunksize=10000, passes=5)\n",
    "## print the most contributing words for n_topic topics\n",
    "print(*lda.print_topics(n_topics), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract 400 LSI topics; use the default one-pass algorithm\n",
    "lsi = g.models.lsimodel.LsiModel(corpus=corpus, id2word=id2word, num_topics=n_topics)\n",
    "# print the most contributing words (both positively and negatively) for each of the first n_topic topics\n",
    "print(*lsi.print_topics(n_topics), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lll = lda\n",
    "index = g.similarities.SparseMatrixSimilarity(lll[corpus], num_features=22)\n",
    "sims = index[lll[id2word.doc2bow(texts[1130])]]\n",
    "print(list(sorted(enumerate(sims), key=lambda t : t[1], reverse=True))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# analyse code part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
